{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HoseinNekouei/sentiment_analysis/blob/main/sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFbexIGRyoGS"
      },
      "outputs": [],
      "source": [
        "pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eosA7fLyoGU",
        "outputId": "adc0966f-452b-4caa-b81f-9896475b3afc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub[hf_xet] in /usr/local/lib/python3.11/dist-packages (0.30.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (4.13.1)\n",
            "Collecting hf-xet>=0.1.4 (from huggingface_hub[hf_xet])\n",
            "  Downloading hf_xet-1.0.3-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (494 bytes)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub[hf_xet]) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub[hf_xet]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub[hf_xet]) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub[hf_xet]) (2025.1.31)\n",
            "Downloading hf_xet-1.0.3-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: hf-xet\n",
            "Successfully installed hf-xet-1.0.3\n"
          ]
        }
      ],
      "source": [
        "pip install huggingface_hub[hf_xet]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfELiPnbJiwU"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.optim import AdamW\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import f1_score, roc_curve, auc\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_linear_schedule_with_warmup\n",
        "\n",
        "HF_TOKEN= ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3lDQ9LwzZbV"
      },
      "outputs": [],
      "source": [
        "import matplotlib.colors as mcolors\n",
        "\n",
        "class ModelMetrics:\n",
        "    @staticmethod\n",
        "    def calculate_metrics(preds, labels):\n",
        "        \"\"\"Calculate accuracy and F1-score for a single fold.\"\"\"\n",
        "        pred_labels = torch.argmax(preds, dim=1)\n",
        "        correct = torch.sum(pred_labels == labels).item()\n",
        "        total = len(labels)\n",
        "        accuracy = correct / total\n",
        "        f1 = f1_score(labels.numpy(), pred_labels.numpy(), average='macro')\n",
        "        return {'accuracy': accuracy, 'f1_score': f1}\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_final_metrics(all_preds, all_labels):\n",
        "        \"\"\"Calculate mean and standard deviation of metrics across all folds.\"\"\"\n",
        "        accuracy_scores = []\n",
        "        f1_scores = []\n",
        "\n",
        "        for preds, labels in zip(all_preds, all_labels):\n",
        "            metrics = ModelMetrics.calculate_metrics(preds, labels)\n",
        "            accuracy_scores.append(metrics['accuracy'])\n",
        "            f1_scores.append(metrics['f1_score'])\n",
        "\n",
        "        accuracy_scores = torch.tensor(accuracy_scores)\n",
        "        f1_scores = torch.tensor(f1_scores)\n",
        "\n",
        "        return {\n",
        "            'mean_accuracy': torch.mean(accuracy_scores),\n",
        "            'std_accuracy': torch.std(accuracy_scores),\n",
        "            'mean_f1': torch.mean(f1_scores),\n",
        "            'std_f1': torch.std(f1_scores)\n",
        "        }\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_mean_roc_curve(all_folds_preds, all_folds_labels, n_classes):\n",
        "        \"\"\"Plot the mean ROC curve across all folds with dynamic colors.\"\"\"\n",
        "        mean_fpr = np.linspace(0, 1, 100)\n",
        "        tprs = [[] for _ in range(n_classes)]\n",
        "        aucs = [[] for _ in range(n_classes)]\n",
        "        colors = list(mcolors.TABLEAU_COLORS.values())[:n_classes]  # Dynamic color selection\n",
        "\n",
        "        for fold_preds, fold_labels in zip(all_folds_preds, all_folds_labels):\n",
        "            for i in range(n_classes):\n",
        "                fpr, tpr, _ = roc_curve(fold_labels.numpy() == i, fold_preds[:, i].numpy())\n",
        "                interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
        "                interp_tpr[0] = 0.0\n",
        "                tprs[i].append(interp_tpr)\n",
        "                aucs[i].append(auc(fpr, tpr))\n",
        "\n",
        "        mean_tpr = [np.mean(tprs[i], axis=0) for i in range(n_classes)]\n",
        "        mean_auc = [np.mean(aucs[i]) for i in range(n_classes)]\n",
        "        std_auc = [np.std(aucs[i]) for i in range(n_classes)]\n",
        "\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        for i in range(n_classes):\n",
        "            plt.plot(mean_fpr, mean_tpr[i], color=colors[i],\n",
        "                     label=f'Class {i} (Mean AUC = {mean_auc[i]:.4f} ± {std_auc[i]:.4f})')\n",
        "            std_tpr = np.std(tprs[i], axis=0)\n",
        "            tprs_upper = np.minimum(mean_tpr[i] + std_tpr, 1)\n",
        "            tprs_lower = np.maximum(mean_tpr[i] - std_tpr, 0)\n",
        "            plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color=colors[i], alpha=0.2)\n",
        "\n",
        "        plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title('Mean ROC Curve Across All Folds (±1 SD)')\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.grid(True)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35sFGVGIsZuM"
      },
      "outputs": [],
      "source": [
        "class SentimentAnalysisModel:\n",
        "    def __init__(self, checkpoint, num_labels=3, epochs=2, batch_size=32, n_splits=2, save_path=None):\n",
        "        \"\"\"Initialize the sentiment analysis model with configurable parameters.\"\"\"\n",
        "        self.checkpoint = checkpoint\n",
        "        self.num_labels = num_labels  # Configurable number of classes\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.n_splits = n_splits\n",
        "        self.save_path = save_path or f\"sentiment_model_{checkpoint.split('/')[-1]}.pt\"\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "        os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"  # Moved import os to top\n",
        "\n",
        "        self.tokenizer, self.model = self.load_model_and_tokenizer()\n",
        "        self.optimizer = AdamW(self.model.parameters(), lr=5e-5)\n",
        "        self.scheduler = None  # Initialized in train_model\n",
        "\n",
        "    def load_model_and_tokenizer(self):\n",
        "        \"\"\"Load tokenizer and model with error handling.\"\"\"\n",
        "        try:\n",
        "            tokenizer = AutoTokenizer.from_pretrained(self.checkpoint)\n",
        "            model = AutoModelForSequenceClassification.from_pretrained(self.checkpoint, num_labels=self.num_labels)\n",
        "            model.to(self.device)\n",
        "            return tokenizer, model\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Failed to load model or tokenizer: {str(e)}\")\n",
        "\n",
        "    def tokenize_texts(self, texts):\n",
        "        \"\"\"Tokenize a list of texts.\"\"\"\n",
        "        if not isinstance(texts, list):\n",
        "            texts = texts.tolist()\n",
        "        encodings = self.tokenizer(\n",
        "            texts,\n",
        "            padding=True,\n",
        "            max_length=256,\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        return encodings\n",
        "\n",
        "    def prepare_dataloaders(self, input_ids, attention_mask, labels, train_idx, validation_idx):\n",
        "        \"\"\"Prepare training and validation dataloaders.\"\"\"\n",
        "        train_dataset = TensorDataset(input_ids[train_idx], attention_mask[train_idx], labels[train_idx])\n",
        "        validation_dataset = TensorDataset(input_ids[validation_idx], attention_mask[validation_idx], labels[validation_idx])\n",
        "        train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
        "        validation_loader = DataLoader(validation_dataset, batch_size=self.batch_size)\n",
        "        return train_loader, validation_loader\n",
        "\n",
        "    def train_model(self, train_loader, fold=0):\n",
        "        \"\"\"Train the model with gradient clipping and learning rate scheduling.\"\"\"\n",
        "        self.model.train()\n",
        "        total_steps = len(train_loader) * self.epochs\n",
        "        self.scheduler = get_linear_schedule_with_warmup(self.optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "        denominator = math.ceil(len(train_loader.dataset) / self.batch_size)  # Computed once\n",
        "        samples_processed = 0  # Track samples for checkpointing\n",
        "        checkpoint_interval = 50000  # Save every 50,000 samples\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "            for i, batch in enumerate(train_loader):\n",
        "                inputs = {k: v.to(self.device) for k, v in zip(['input_ids', 'attention_mask', 'labels'], batch)}\n",
        "                self.optimizer.zero_grad()\n",
        "                outputs = self.model(**inputs)\n",
        "                loss = outputs.loss\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)  # Gradient clipping\n",
        "                self.optimizer.step()\n",
        "                self.scheduler.step()\n",
        "\n",
        "                # Update samples processed\n",
        "                samples_processed += self.batch_size\n",
        "\n",
        "                # Checkpoint every 50,000 samples\n",
        "                if samples_processed >= checkpoint_interval:\n",
        "                    checkpoint_dir = os.path.join(\"checkpoints\", f\"fold_{fold}\", f\"samples_{samples_processed}\")\n",
        "                    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "                    try:\n",
        "                        # Save model, optimizer, scheduler, and metadata\n",
        "                        torch.save(self.model.state_dict(), os.path.join(checkpoint_dir, \"model.pt\"))\n",
        "                        torch.save(self.optimizer.state_dict(), os.path.join(checkpoint_dir, \"optimizer.pt\"))\n",
        "                        torch.save(self.scheduler.state_dict(), os.path.join(checkpoint_dir, \"scheduler.pt\"))\n",
        "                        torch.save({\n",
        "                            'epoch': epoch,\n",
        "                            'batch': i + 1,\n",
        "                            'samples_processed': samples_processed,\n",
        "                            'loss': loss.item()\n",
        "                        }, os.path.join(checkpoint_dir, \"training_state.pt\"))\n",
        "                        print(f\"Saved checkpoint at {checkpoint_dir} after {samples_processed} samples\")\n",
        "\n",
        "                        # Reset samples_processed for next checkpoint\n",
        "                        samples_processed = samples_processed % checkpoint_interval\n",
        "                    except Exception as e:\n",
        "                        print(f\"Failed to save checkpoint: {str(e)}\")\n",
        "\n",
        "\n",
        "                if (i + 1) % 100 == 0:\n",
        "                    print(f'[Epoch: {epoch + 1}] -> Batch: [{i + 1}/{denominator}]')\n",
        "            print(f'[Epoch: {epoch + 1}] -> Batch: [{denominator}/{denominator}]')\n",
        "\n",
        "    def evaluate_model(self, validation_loader):\n",
        "        \"\"\"Evaluate the model and move tensors to CPU to manage memory.\"\"\"\n",
        "        self.model.eval()\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in validation_loader:\n",
        "                inputs = {k: v.to(self.device) for k, v in zip(['input_ids', 'attention_mask'], batch[:-1])}\n",
        "                labels_batch = batch[-1].to(self.device)\n",
        "                outputs = self.model(**inputs)\n",
        "                probs = torch.softmax(outputs.logits, dim=1)\n",
        "                all_preds.append(probs.cpu())  # Move to CPU immediately\n",
        "                all_labels.append(labels_batch.cpu())\n",
        "\n",
        "        return torch.cat(all_preds, dim=0), torch.cat(all_labels, dim=0)\n",
        "\n",
        "    def kfold_cross_validation(self, train_data):\n",
        "        \"\"\"Perform k-fold cross-validation with improved robustness.\"\"\"\n",
        "        texts = train_data['text']\n",
        "        labels = torch.tensor(train_data['labels'].tolist()).to(self.device)\n",
        "\n",
        "        print(\"Unique labels in dataset:\", torch.unique(labels))\n",
        "        print(\"Label value range:\", labels.min(), labels.max())\n",
        "        assert labels.min() >= 0 and labels.max() < self.num_labels, f\"Labels must be between 0 and {self.num_labels - 1}\"\n",
        "\n",
        "        encodings = self.tokenize_texts(texts)\n",
        "        input_ids = encodings['input_ids'].to(self.device)\n",
        "        attention_mask = encodings['attention_mask'].to(self.device)\n",
        "\n",
        "        kfold = KFold(n_splits=self.n_splits, shuffle=True, random_state=42)\n",
        "        all_preds_by_fold = []\n",
        "        all_labels_by_fold = []\n",
        "\n",
        "        for fold, (train_idx, validation_idx) in enumerate(kfold.split(input_ids)):\n",
        "            print(f\"\\nFold {fold + 1}/{self.n_splits}\")\n",
        "            train_loader, validation_loader = self.prepare_dataloaders(input_ids, attention_mask, labels, train_idx, validation_idx)\n",
        "\n",
        "            self.train_model(train_loader, fold= fold)\n",
        "            fold_preds, fold_labels = self.evaluate_model(validation_loader)\n",
        "            all_preds_by_fold.append(fold_preds)\n",
        "            all_labels_by_fold.append(fold_labels)\n",
        "\n",
        "            metrics = ModelMetrics.calculate_metrics(fold_preds, fold_labels)\n",
        "            print(f\"Validation Accuracy: {metrics['accuracy']:.4f}\")\n",
        "            print(f\"Validation F1-Score: {metrics['f1_score']:.4f}\")\n",
        "            print('=' * 30)\n",
        "\n",
        "        final_metrics = ModelMetrics.calculate_final_metrics(all_preds_by_fold, all_labels_by_fold)\n",
        "        print(f\"\\nFinal Results:\")\n",
        "        print(f\"Mean accuracy: {final_metrics['mean_accuracy']:.4f} ± {final_metrics['std_accuracy']:.4f}\")\n",
        "        print(f\"Mean F1-score: {final_metrics['mean_f1']:.4f} ± {final_metrics['std_f1']:.4f}\")\n",
        "\n",
        "        ModelMetrics.plot_mean_roc_curve(all_preds_by_fold, all_labels_by_fold, self.num_labels)\n",
        "\n",
        "        try:\n",
        "            torch.save(self.model.state_dict(), self.save_path)\n",
        "            print(f\"\\nModel saved to {self.save_path}!\")\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to save model: {str(e)}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JpB_cJZkq86"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def load_data(file_path, nrows=None):\n",
        "    \"\"\"Load data from a CSV file with error handling.\"\"\"\n",
        "    try:\n",
        "        file_size = os.path.getsize(file_path) / (1024 * 1024)  # Size in MB\n",
        "        print(f\"File size: {file_size:.2f} MB\")\n",
        "        print(f\"Total lines (including header): {sum(1 for line in open(file_path, 'r', encoding='utf-8'))}\")\n",
        "\n",
        "        data = pd.read_csv(file_path, nrows=nrows, encoding='utf-8')\n",
        "        data['labels']= data['labels'].apply(lambda x: 0 if x==1 else 1)\n",
        "\n",
        "        print(\"Data loaded successfully:\")\n",
        "        print(data.info())\n",
        "        return data\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File not found at {file_path}\")\n",
        "        sys.exit(1)\n",
        "    except pd.errors.EmptyDataError:\n",
        "        print(f\"Error: File at {file_path} is empty\")\n",
        "        sys.exit(1)\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading data: {str(e)}\")\n",
        "        sys.exit(1)\n",
        "\n",
        "def get_config():\n",
        "    \"\"\"Return a configuration dictionary with training parameters.\"\"\"\n",
        "    return {\n",
        "        'nrows': 100,\n",
        "        'n_splits': 5,\n",
        "        'epochs': 2,\n",
        "        'batch_size': 32,\n",
        "        'num_labels': 2,\n",
        "        'checkpoint': 'FacebookAI/roberta-base',\n",
        "        'file_path': '/content/aspected_yelp_train_corpus.csv',\n",
        "    }\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to orchestrate the sentiment analysis process.\"\"\"\n",
        "    # Load configuration\n",
        "    config = get_config()\n",
        "\n",
        "    file_path = config['file_path']\n",
        "\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"Error: {config['file_path']} no exists.\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    # Load data\n",
        "    train_data = load_data(file_path, nrows=config['nrows'])\n",
        "\n",
        "    # Initialize and train the model\n",
        "    try:\n",
        "        model = SentimentAnalysisModel(\n",
        "            checkpoint=config['checkpoint'],\n",
        "            epochs=config['epochs'],\n",
        "            batch_size=config['batch_size'],\n",
        "            n_splits=config['n_splits'],\n",
        "            num_labels= config['num_labels'],\n",
        "            save_path=f\"trained_model_{config['checkpoint'].split('/')[-1]}.pt\"\n",
        "        )\n",
        "        model.kfold_cross_validation(train_data)\n",
        "    except Exception as e:\n",
        "        print(f\"Error during model training: {str(e)}\")\n",
        "        sys.exit(1)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8yftNxwFRYd",
        "outputId": "c4105fca-7ba6-4a4c-f6be-5802f8e030c9"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WY5xsQZSDP8D",
        "outputId": "6ebd258a-4164-48f7-e442-9acf565f09cf"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File size: 5.00 MB\n",
            "Total lines (including header): 6371\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0ZlHX2Cq7i9y"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
