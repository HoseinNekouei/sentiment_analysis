{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11450499,"sourceType":"datasetVersion","datasetId":7174156}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install huggingface_hub[hf_xet]","metadata":{"id":"BFbexIGRyoGS","trusted":true,"execution":{"iopub.status.busy":"2025-04-21T08:43:59.921608Z","iopub.execute_input":"2025-04-21T08:43:59.921909Z","iopub.status.idle":"2025-04-21T08:44:06.106480Z","shell.execute_reply.started":"2025-04-21T08:43:59.921884Z","shell.execute_reply":"2025-04-21T08:44:06.105806Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: huggingface_hub[hf_xet] in /usr/local/lib/python3.11/dist-packages (0.30.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (2025.3.2)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (4.13.1)\nCollecting hf-xet>=0.1.4 (from huggingface_hub[hf_xet])\n  Downloading hf_xet-1.0.3-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (494 bytes)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub[hf_xet]) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub[hf_xet]) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub[hf_xet]) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub[hf_xet]) (2025.1.31)\nDownloading hf_xet-1.0.3-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: hf-xet\nSuccessfully installed hf-xet-1.0.3\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import math\nimport pandas as pd\nimport torch\nimport numpy as np\nfrom torch.optim import AdamW\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import f1_score, roc_curve, auc\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, get_linear_schedule_with_warmup\n\n#your own Huggingface Token\nHF_TOKEN= '...'","metadata":{"id":"AfELiPnbJiwU","trusted":true,"execution":{"iopub.status.busy":"2025-04-21T08:44:06.108060Z","iopub.execute_input":"2025-04-21T08:44:06.108282Z","iopub.status.idle":"2025-04-21T08:44:14.942581Z","shell.execute_reply.started":"2025-04-21T08:44:06.108262Z","shell.execute_reply":"2025-04-21T08:44:14.942017Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import matplotlib.colors as mcolors\n\nclass ModelMetrics:\n    @staticmethod\n    def calculate_metrics(preds, labels):\n        \"\"\"Calculate accuracy and F1-score for a single fold.\"\"\"\n        pred_labels = torch.argmax(preds, dim=1)\n        correct = torch.sum(pred_labels == labels).item()\n        total = len(labels)\n        accuracy = correct / total\n        f1 = f1_score(labels.numpy(), pred_labels.numpy(), average='macro')\n        return {'accuracy': accuracy, 'f1_score': f1}\n\n    @staticmethod\n    def calculate_final_metrics(all_preds, all_labels):\n        \"\"\"Calculate mean and standard deviation of metrics across all folds.\"\"\"\n        accuracy_scores = []\n        f1_scores = []\n\n        for preds, labels in zip(all_preds, all_labels):\n            metrics = ModelMetrics.calculate_metrics(preds, labels)\n            accuracy_scores.append(metrics['accuracy'])\n            f1_scores.append(metrics['f1_score'])\n\n        accuracy_scores = torch.tensor(accuracy_scores)\n        f1_scores = torch.tensor(f1_scores)\n\n        return {\n            'mean_accuracy': torch.mean(accuracy_scores),\n            'std_accuracy': torch.std(accuracy_scores),\n            'mean_f1': torch.mean(f1_scores),\n            'std_f1': torch.std(f1_scores)\n        }\n\n    @staticmethod\n    def plot_mean_roc_curve(all_folds_preds, all_folds_labels, n_classes):\n        \"\"\"Plot the mean ROC curve across all folds with dynamic colors.\"\"\"\n        mean_fpr = np.linspace(0, 1, 100)\n        tprs = [[] for _ in range(n_classes)]\n        aucs = [[] for _ in range(n_classes)]\n        colors = list(mcolors.TABLEAU_COLORS.values())[:n_classes]  # Dynamic color selection\n\n        for fold_preds, fold_labels in zip(all_folds_preds, all_folds_labels):\n            for i in range(n_classes):\n                fpr, tpr, _ = roc_curve(fold_labels.numpy() == i, fold_preds[:, i].numpy())\n                interp_tpr = np.interp(mean_fpr, fpr, tpr)\n                interp_tpr[0] = 0.0\n                tprs[i].append(interp_tpr)\n                aucs[i].append(auc(fpr, tpr))\n\n        mean_tpr = [np.mean(tprs[i], axis=0) for i in range(n_classes)]\n        mean_auc = [np.mean(aucs[i]) for i in range(n_classes)]\n        std_auc = [np.std(aucs[i]) for i in range(n_classes)]\n\n        plt.figure(figsize=(10, 8))\n        for i in range(n_classes):\n            plt.plot(mean_fpr, mean_tpr[i], color=colors[i],\n                     label=f'Class {i} (Mean AUC = {mean_auc[i]:.4f} ± {std_auc[i]:.4f})')\n            std_tpr = np.std(tprs[i], axis=0)\n            tprs_upper = np.minimum(mean_tpr[i] + std_tpr, 1)\n            tprs_lower = np.maximum(mean_tpr[i] - std_tpr, 0)\n            plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color=colors[i], alpha=0.2)\n\n        plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')\n        plt.xlabel('False Positive Rate')\n        plt.ylabel('True Positive Rate')\n        plt.title('Mean ROC Curve Across All Folds (±1 SD)')\n        plt.legend(loc=\"lower right\")\n        plt.grid(True)\n        plt.show()","metadata":{"id":"z3lDQ9LwzZbV","trusted":true,"execution":{"iopub.status.busy":"2025-04-21T08:44:14.943295Z","iopub.execute_input":"2025-04-21T08:44:14.943705Z","iopub.status.idle":"2025-04-21T08:44:14.954734Z","shell.execute_reply.started":"2025-04-21T08:44:14.943687Z","shell.execute_reply":"2025-04-21T08:44:14.954048Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import os\nimport torch.amp\nimport time\n\nclass SentimentAnalysisModel:\n    def __init__(self, checkpoint, num_labels=3, epochs=2, batch_size=32, n_splits=5, save_path=None):\n        \"\"\"Initialize the sentiment analysis model for single-GPU training.\"\"\"\n        os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n        self.checkpoint = checkpoint\n        self.num_labels = num_labels\n        self.epochs = epochs\n        self.batch_size = batch_size\n        self.n_splits = n_splits\n        self.save_path = save_path or f\"sentiment_model_{checkpoint.split('/')[-1]}.pt\"\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        \n        # Load model (tokenizer not needed since pre-tokenized)\n        self.model = self.load_model()\n        \n        print(f\"Using device: {self.device} (Single GPU)\")\n        self.optimizer = AdamW(self.model.parameters(), lr=5e-5)\n        self.scheduler = None\n\n    def load_model(self):\n        \"\"\"Load model with error handling.\"\"\"\n        try:\n            model = AutoModelForSequenceClassification.from_pretrained(\n                self.checkpoint, num_labels=self.num_labels\n            )\n            model.to(self.device)\n            return model\n        except Exception as e:\n            raise RuntimeError(f\"Failed to load model: {str(e)}\")\n\n    def prepare_dataloaders(self, input_ids, attention_mask, labels, train_idx, validation_idx):\n        train_dataset = TensorDataset(input_ids[train_idx], attention_mask[train_idx], labels[train_idx])\n        validation_dataset = TensorDataset(input_ids[validation_idx], attention_mask[validation_idx], labels[validation_idx])\n        train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=2, pin_memory=True)\n        validation_loader = DataLoader(validation_dataset, batch_size=256, num_workers=0, pin_memory=True)  # Larger batch size for validation\n        return train_loader, validation_loader\n    \n    def train_model(self, train_loader):\n        self.model.train()\n        total_steps = len(train_loader) * self.epochs\n        self.scheduler = get_linear_schedule_with_warmup(self.optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n        scaler = torch.amp.GradScaler('cuda')\n        denominator = math.ceil(len(train_loader.dataset) / self.batch_size)\n        accumulation_steps = 2  # Effective batch size = 64 * 2 = 128\n    \n        for epoch in range(self.epochs):\n            epoch_start = time.time()\n            for i, batch in enumerate(train_loader):\n                input_ids, attention_mask, labels = batch\n                input_ids, attention_mask, labels = input_ids.to(self.device), attention_mask.to(self.device), labels.to(self.device)\n                inputs = {'input_ids': input_ids, 'attention_mask': attention_mask, 'labels': labels}\n    \n                self.optimizer.zero_grad(set_to_none=True)  # Optimize memory\n                with torch.amp.autocast('cuda'):\n                    outputs = self.model(**inputs)\n                    loss = outputs.loss / accumulation_steps  # Normalize loss\n                scaler.scale(loss).backward()\n    \n                if (i + 1) % accumulation_steps == 0:\n                    # scaler.unscale_(self.optimizer)\n                    if (i + 1) % 50 == 0:\n                        torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n                    scaler.step(self.optimizer)\n                    scaler.update()\n                    self.scheduler.step()\n    \n                if (i + 1) % 100 == 0:\n                    print(f'[Epoch: {epoch + 1}] -> Batch: [{i + 1}/{denominator}]')\n            print(f'[Epoch: {epoch + 1}] -> Batch: [{denominator}/{denominator}]')\n            print(f'Epoch {epoch + 1} took {time.time() - epoch_start:.2f} seconds')\n\n    def evaluate_model(self, validation_loader):\n        \"\"\"Evaluate the model and move tensors to CPU to manage memory.\"\"\"\n        self.model.eval()\n        all_preds = []\n        all_labels = []\n\n        with torch.no_grad():\n            for batch in validation_loader:\n                # Move batch to GPU after DataLoader fetches it\n                inputs = {k: v.to(self.device) for k, v in zip(['input_ids', 'attention_mask'], batch[:-1])}\n                labels_batch = batch[-1].to(self.device)\n                outputs = self.model(**inputs)\n                probs = torch.softmax(outputs.logits, dim=1)\n                all_preds.append(probs.cpu())\n                all_labels.append(labels_batch.cpu())\n\n        return torch.cat(all_preds, dim=0), torch.cat(all_labels, dim=0)\n\n    def kfold_cross_validation(self, data_dict):\n        \"\"\"Perform k-fold cross-validation with pre-tokenized data.\"\"\"\n        train_data = data_dict['data']\n        # Keep tensors on CPU for DataLoader; move to GPU in train/evaluate\n        input_ids = data_dict['input_ids']  # Already on CPU from load_data\n        attention_mask = data_dict['attention_mask']  # Already on CPU\n        labels = torch.tensor(train_data['labels'].tolist())  # Keep on CPU\n\n        print(\"Unique labels in dataset:\", torch.unique(labels))\n        print(\"Label value range:\", labels.min(), labels.max())\n        assert labels.min() >= 0 and labels.max() < self.num_labels, \\\n            f\"Labels must be between 0 and {self.num_labels - 1}\"\n\n        kfold = KFold(n_splits=self.n_splits, shuffle=True, random_state=42)\n        all_preds_by_fold = []\n        all_labels_by_fold = []\n\n        for fold, (train_idx, validation_idx) in enumerate(kfold.split(input_ids)):\n            print(f\"\\nFold {fold + 1}/{self.n_splits}\")\n            train_loader, validation_loader = self.prepare_dataloaders(\n                input_ids, attention_mask, labels, train_idx, validation_idx\n            )\n            self.train_model(train_loader)\n            fold_preds, fold_labels = self.evaluate_model(validation_loader)\n            all_preds_by_fold.append(fold_preds)\n            all_labels_by_fold.append(fold_labels)\n\n            metrics = ModelMetrics.calculate_metrics(fold_preds, fold_labels)\n            print(f\"Validation Accuracy: {metrics['accuracy']:.4f}\")\n            print(f\"Validation F1-Score: {metrics['f1_score']:.4f}\")\n            print('=' * 30)\n\n        final_metrics = ModelMetrics.calculate_final_metrics(all_preds_by_fold, all_labels_by_fold)\n        print(f\"\\nFinal Results:\")\n        print(f\"Mean accuracy: {final_metrics['mean_accuracy']:.4f} ± {final_metrics['std_accuracy']:.4f}\")\n        print(f\"Mean F1-score: {final_metrics['mean_f1']:.4f} ± {final_metrics['std_f1']:.4f}\")\n\n        ModelMetrics.plot_mean_roc_curve(all_preds_by_fold, all_labels_by_fold, self.num_labels)\n\n        try:\n            torch.save(self.model.state_dict(), self.save_path)\n            print(f\"\\nModel saved to {self.save_path}!\")\n        except Exception as e:\n            print(f\"Failed to save model: {str(e)}\")","metadata":{"id":"35sFGVGIsZuM","trusted":true,"execution":{"iopub.status.busy":"2025-04-21T08:44:14.955631Z","iopub.execute_input":"2025-04-21T08:44:14.955938Z","iopub.status.idle":"2025-04-21T08:44:14.998085Z","shell.execute_reply.started":"2025-04-21T08:44:14.955911Z","shell.execute_reply":"2025-04-21T08:44:14.997367Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T08:44:14.999492Z","iopub.execute_input":"2025-04-21T08:44:14.999747Z","iopub.status.idle":"2025-04-21T08:44:15.026299Z","shell.execute_reply.started":"2025-04-21T08:44:14.999725Z","shell.execute_reply":"2025-04-21T08:44:15.025504Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/yelp-corpus-aspected/aspected_yelp_train_corpus.csv\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import os\nimport time\n\n# Set environment to use only one GPU (GPU 0)\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n# Disable tokenizers parallelism to avoid warnings during DataLoader forking\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\ndef load_data(file_path, tokenizer, nrows=None, label_column='labels'):\n    \"\"\"Load, balance, and pre-tokenize data from a CSV file.\n\n    Args:\n        file_path (str): Path to the CSV file.\n        tokenizer: Hugging Face tokenizer for pre-tokenizing texts.\n        nrows (int, optional): Number of rows to read.\n        label_column (str): Name of the column containing labels.\n\n    Returns:\n        dict: Contains 'data' (balanced DataFrame), 'input_ids', and 'attention_mask'.\n    \"\"\"\n    try:\n        # Read CSV\n        data = pd.read_csv(file_path, nrows=nrows, encoding='utf-8')\n        \n        # Validate required columns\n        required_columns = ['text', label_column]\n        missing_columns = [col for col in required_columns if col not in data.columns]\n        if missing_columns:\n            print(f\"Error: Missing columns {missing_columns}. Available columns: {list(data.columns)}\")\n            raise SystemExit(1)\n        \n        # Check unique label values\n        unique_labels = data[label_column].unique()\n        print(f\"Unique labels in dataset: {unique_labels}\")\n        \n        # Map labels explicitly for binary classification\n        if set(unique_labels).issubset({0, 1}):\n            print(\"Labels are already 0 and 1; no mapping needed.\")\n        elif set(unique_labels).issubset({1, 2}):\n            print(\"Mapping labels: 1 -> 0, 2 -> 1\")\n            data[label_column] = data[label_column].map({1: 0, 2: 1})\n        else:\n            print(f\"Error: Unexpected label values {unique_labels}. Expected 0/1 or 1/2 for binary classification.\")\n            raise SystemExit(1)\n        \n        # Balance dataset (40000 samples per label)\n        n_samples_per_group = 50000\n        # Group by labels and sample indices\n        sampled_indices = []\n        for label, group in data.groupby(label_column):\n            sample_size = min(n_samples_per_group, len(group))\n            sampled_indices.extend(group.sample(n=sample_size, random_state=42).index)\n        # Create balanced DataFrame using the sampled indices\n        balanced_data = data.loc[sampled_indices].reset_index(drop=True)\n        \n        # Pre-tokenize texts\n        texts = balanced_data['text'].tolist()\n        encodings = tokenizer(\n            texts,\n            padding=True,\n            max_length= 128,\n            truncation=True,\n            return_tensors='pt'\n        )\n        input_ids = encodings['input_ids']\n        attention_mask = encodings['attention_mask']\n        \n        print(\"Balanced data info:\")\n        print(balanced_data.info())\n        print(\"Label distribution:\")\n        print(balanced_data[label_column].value_counts())\n        print(f\"Input IDs shape: {input_ids.shape}\")\n        print(f\"Attention mask shape: {attention_mask.shape}\")\n        \n        return {\n            'data': balanced_data,\n            'input_ids': input_ids,\n            'attention_mask': attention_mask\n        }\n    \n    except FileNotFoundError:\n        print(f\"Error: File not found at {file_path}\")\n        raise SystemExit(1)\n    except pd.errors.EmptyDataError:\n        print(f\"Error: Empty CSV file at {file_path}\")\n        raise SystemExit(1)\n    except Exception as e:\n        print(f\"Error loading data: {e}\")\n        raise SystemExit(1)\n\ndef main():\n    \"\"\"Run the sentiment analysis pipeline on a single GPU.\"\"\"\n    start_time = time.time()\n    \n    # Configuration\n    config = {\n        'file_path': '../input/yelp-corpus-aspected/aspected_yelp_train_corpus.csv',\n        'nrows': None,\n        'checkpoint': 'FacebookAI/roberta-base',\n        'num_labels': 2,\n        'epochs': 2,\n        'batch_size': 192,\n        'n_splits': 5,\n        'save_path': '../working/trained_model_roberta-base_k5.pt',\n        'label_column': 'labels'\n    }\n    \n    # Initialize tokenizer for pre-tokenization\n    tokenizer = AutoTokenizer.from_pretrained(config['checkpoint'])\n    \n    # Load and pre-tokenize data\n    data_dict = load_data(config['file_path'], tokenizer, config['nrows'], config['label_column'])\n    \n    # Validate loaded data\n    if not isinstance(data_dict, dict) or 'data' not in data_dict or 'input_ids' not in data_dict or 'attention_mask' not in data_dict:\n        print(\"Error: load_data must return a dictionary with 'data', 'input_ids', and 'attention_mask' keys\")\n        raise SystemExit(1)\n    if not isinstance(data_dict['data'], pd.DataFrame):\n        print(\"Error: data_dict['data'] must be a pandas DataFrame\")\n        raise SystemExit(1)\n    \n    print(f\"Data loading took {time.time() - start_time:.2f} seconds\")\n    \n    # Train model\n    model = SentimentAnalysisModel(\n        checkpoint=config['checkpoint'],\n        num_labels=config['num_labels'],\n        epochs=config['epochs'],\n        batch_size=config['batch_size'],\n        n_splits=config['n_splits'],\n        save_path=config['save_path']\n    )\n    model.kfold_cross_validation(data_dict)\n    print(f\"Total runtime: {time.time() - start_time:.2f} seconds\")\n\n\nif __name__ == \"__main__\":\n    try:\n        main()\n    except SystemExit as e:\n        print(f\"Script exited with code: {e.code}\")\n        raise\n    except Exception as e:\n        print(f\"Unexpected error: {e}\")\n        raise","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T08:44:15.027001Z","iopub.execute_input":"2025-04-21T08:44:15.027234Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ea7ed6f5805461b92d1804890b8ef86"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5eb4bd1d4c4a446cb52e3504f7a10228"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4bd44c91c58f479bb34c861a4a368e6b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e947f79a99f40bfad75c8f51fc1add2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5d1f132b16d433ca12f6cce623c7cf4"}},"metadata":{}},{"name":"stdout","text":"Unique labels in dataset: [1 2]\nMapping labels: 1 -> 0, 2 -> 1\nBalanced data info:\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 100000 entries, 0 to 99999\nData columns (total 2 columns):\n #   Column  Non-Null Count   Dtype \n---  ------  --------------   ----- \n 0   text    100000 non-null  object\n 1   labels  100000 non-null  int64 \ndtypes: int64(1), object(1)\nmemory usage: 1.5+ MB\nNone\nLabel distribution:\nlabels\n0    50000\n1    50000\nName: count, dtype: int64\nInput IDs shape: torch.Size([100000, 128])\nAttention mask shape: torch.Size([100000, 128])\nData loading took 70.69 seconds\n","output_type":"stream"},{"name":"stderr","text":"2025-04-21 08:45:32.277057: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745225132.507292      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1745225132.572308      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be74b3e8949f46f2a4630cc8b5288428"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Using device: cuda (Single GPU)\nUnique labels in dataset: tensor([0, 1])\nLabel value range: tensor(0) tensor(1)\n\nFold 1/5\n[Epoch: 1] -> Batch: [100/417]\n[Epoch: 1] -> Batch: [200/417]\n","output_type":"stream"}],"execution_count":null}]}